{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hybrid Search with BM25 and KNN on Amazon Opensearch Serverless"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --no-build-isolation --force-reinstall \\\n",
    "    \"boto3>=1.28.57\" \\\n",
    "    \"awscli>=1.29.57\" \\\n",
    "    \"botocore>=1.31.57\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U opensearch-py==2.3.1 langchain==0.0.309"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries and initialize client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import os \n",
    "from langchain.embeddings import BedrockEmbeddings\n",
    "from langchain.llms.bedrock import Bedrock\n",
    "from opensearchpy import OpenSearch, RequestsHttpConnection, AWSV4SignerAuth\n",
    "\n",
    "target_region = os.environ.get(\"AWS_REGION\", os.environ.get(\"AWS_DEFAULT_REGION\"))\n",
    "boto3_bedrock_runtime = boto3.Session(region_name=target_region).client(\"bedrock-runtime\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INDEX_NAME = \"<Replace this with Amazon Open Search Serverless Index name>\"\n",
    "VECTOR_STORE_COLLECTION = \"<Replace this with Amazon Open Search Serverless Collection Host and Port>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "service = 'aoss'\n",
    "credentials = boto3.Session().get_credentials()\n",
    "auth = AWSV4SignerAuth(credentials, os.environ.get(\"AWS_DEFAULT_REGION\", None), service)\n",
    "\n",
    "\n",
    "# Create the client with SSL/TLS enabled, but hostname verification disabled.\n",
    "os_client = OpenSearch(\n",
    "    hosts = [VECTOR_STORE_COLLECTION],\n",
    "    http_auth=auth,\n",
    "    timeout = 100,\n",
    "    use_ssl = True,\n",
    "    verify_certs = True,\n",
    "    connection_class = RequestsHttpConnection,\n",
    "    index_name=INDEX_NAME,\n",
    "    engine=\"faiss\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = \"What are manufacturing best practices ?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the embeddings for the quety"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bedrock_embeddings = BedrockEmbeddings(client=boto3_bedrock_runtime)\n",
    "query_embedding = bedrock_embeddings.embed_query(q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hybrid Search matching both BM25 and KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_query = {\n",
    "  \"_source\": [\"text\"],   \n",
    "  \"query\": {\n",
    "        \"bool\": {\n",
    "          \"should\": [\n",
    "            {\n",
    "              \"match\": {\n",
    "                 \"text\": {\n",
    "                    \"query\": q,\n",
    "                    \"fuzziness\": \"AUTO\",\n",
    "                    \"boost\": 0.25,\n",
    "                    \"_name\" : \"BM25_Match\"  \n",
    "                  }\n",
    "              }\n",
    "            },\n",
    "            {\n",
    "              \"knn\": {\n",
    "                   \"vector_field\": {\n",
    "                  \"vector\": query_embedding,\n",
    "                  \"k\": 2,\n",
    "                  \"boost\": 2,\n",
    "                  \"_name\" : \"KNN_Match\"\n",
    "                }\n",
    "              }\n",
    "            }\n",
    "          ]\n",
    "        }\n",
    "      }\n",
    "}\n",
    "os_client.search(combined_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalized Weigthed Hybrid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BM25 Based Query :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_bm25 = {\n",
    "    \"_source\": [\"text\"],\n",
    "    \"query\": {\n",
    "        \"match\": {\n",
    "          \"text\": {\n",
    "            \"query\": q,\n",
    "            \"fuzziness\": \"AUTO\"\n",
    "          }\n",
    "        }\n",
    "  }\n",
    "             }\n",
    "bm25_results = os_client.search(query_bm25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN Based Query :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_knn = {\n",
    "    \"_source\": [\"text\"],\n",
    "    \"size\": 2,\n",
    "    \"query\": {\n",
    "        \"knn\": {\n",
    "            \"vector_field\": {\n",
    "                \"vector\": query_embedding, \n",
    "                \"k\": 2\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "}\n",
    "\n",
    "knn_results = os_client.search(query_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize the Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_scores(results):\n",
    "    scores = [hit['_score'] for hit in results['hits']['hits']]\n",
    "    min_score, max_score = min(scores), max(scores)\n",
    "    return {hit['_id']: (hit['_score'] - min_score) / (max_score - min_score) if max_score > min_score else 0\n",
    "            for hit in results['hits']['hits']}\n",
    "    \n",
    "normalized_bm25_scores = normalize_scores(bm25_results)\n",
    "normalized_knn_scores = normalize_scores(knn_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine the Scores based on weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your weights\n",
    "w_bm25 = 0.25\n",
    "w_knn = 0.75\n",
    "\n",
    "combined_scores = {}\n",
    "for doc_id in set(normalized_bm25_scores.keys()).union(normalized_knn_scores.keys()):\n",
    "    combined_scores[doc_id] = w_bm25 * normalized_bm25_scores.get(doc_id, 0) \\\n",
    "                            + w_knn * normalized_knn_scores.get(doc_id, 0)\n",
    "\n",
    "# Sort combined scores\n",
    "sorted_combined_scores = sorted(combined_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "sorted_combined_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
